<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Here Comes the Sun</title><link href="https://sunng.info/blog/" rel="alternate"></link><link href="https://sunng.info/blog/atom.xml" rel="self"></link><id>https://sunng.info/blog/</id><updated>2016-03-21T22:28:06+08:00</updated><entry><title>"Smoothing Your Rust Crates Release With Cargo-release"</title><link href="https://sunng.info/blog/smoothing-your-rust-crates-release-with-cargo-release.html" rel="alternate"></link><updated>2016-03-21T22:28:06+08:00</updated><author><name>Ning Sun</name></author><id>tag:sunng.info,2016-03-21:blog/smoothing-your-rust-crates-release-with-cargo-release.html</id><summary type="html">&lt;p&gt;Cargo-release is a cargo subcommand that automates your libraries
release process. The idea was inspired by Clojure's leiningen, which
has a &lt;code&gt;release&lt;/code&gt; command does exact same thing.&lt;/p&gt;
&lt;p&gt;Typically, when you decide to release a library to crates.io, you need
to go through following steps at least:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bump version in Cargo.toml&lt;/li&gt;
&lt;li&gt;create a git tag for the release&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;cargo publish&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;push tags/commits to github&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cargo-release command deals these tasks for you. In addition, it
increases your patch version and add a &lt;code&gt;pre&lt;/code&gt; extension after &lt;code&gt;cargo
publish&lt;/code&gt;. The Java/Maven world uses a &lt;code&gt;SNAPSHOT&lt;/code&gt; version for
pre-release. What's sad, no other package manager follows this great
idea. With this pre-release extension, users are able to tell if your
master branch is on a released version or not.&lt;/p&gt;
&lt;p&gt;By default, cargo-release removes pre-release extension as the version
to release. You can override this behavior by a &lt;code&gt;--level&lt;/code&gt;. The value
for &lt;code&gt;--level&lt;/code&gt; can be &lt;code&gt;major&lt;/code&gt;, &lt;code&gt;minor&lt;/code&gt; or &lt;code&gt;patch&lt;/code&gt;. As the name
suggests, it increases different part of a semver version.&lt;/p&gt;
&lt;p&gt;For multi-crates repository, &lt;code&gt;cargo-release&lt;/code&gt; reads you sub-directory
name and use it as prefix of git tag to avoid conflicts.&lt;/p&gt;
&lt;p&gt;Some more features are planned for this tool, for instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Custom tag prefix&lt;/li&gt;
&lt;li&gt;Build docs and push to gh-pages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I hope this tool can be used as a standard of rust library release
process. You can install this tool by &lt;code&gt;cargo install
cargo-release&lt;/code&gt;. And the github repo is
&lt;a href="https://github.com/sunng87/cargo-release"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="rust"></category><category term="programming"></category></entry><entry><title>"Summarizing Changes in Slacker 0.13"</title><link href="https://sunng.info/blog/summarizing-changes-in-slacker-013.html" rel="alternate"></link><updated>2015-10-18T13:45:37+08:00</updated><author><name>Ning Sun</name></author><id>tag:sunng.info,2015-10-18:blog/summarizing-changes-in-slacker-013.html</id><summary type="html">&lt;p&gt;After a year of feature development and minor fixes, &lt;a href="https://github.com/sunng87/slacker"&gt;Slacker&lt;/a&gt; and &lt;a href="https://github.com/sunng87/slacker-cluster"&gt;Slacker Cluster&lt;/a&gt; version 0.13 is now available. In this article, I will summarize changes in this release and give a you short introduction of new features and improvements.&lt;/p&gt;
&lt;p&gt;Slacker is an RPC framework features non-invasive design. It exposes clojure namespace as remote service, and keeps your remote invocation as simple as local version. Slacker cluster uses Zookeeper for service discovery, helps you to build micro-service based architecture. The grouping function gives you full control over request routing.&lt;/p&gt;
&lt;h3&gt;Application managed thread pool&lt;/h3&gt;
&lt;p&gt;During 0.12 series, Slacker server uses Netty managed thread pool for task execution. Netty assign a single thread from its pool to a connection. The thread will be used for all requests from the connection. And these requests will be processed in a serial manner. This works perfect for non-blocking tasks. However, if your tasks are data-intensive, this causes head-of-line blocking issue.&lt;/p&gt;
&lt;p&gt;The Netty design is to keep request/esponse ordered for a connection. Slacker uses multiplex on its connection, so ordering is not an issue. In 0.13, we now use an application managed thread pool for task execution. You can still configure the pool size by &lt;code&gt;:threads&lt;/code&gt; option. If your tasks are non-blocking ones, just set the threads equals your cores. Otherwise, you can customize the size based on blocking time of your tasks.&lt;/p&gt;
&lt;h3&gt;Interrupt&lt;/h3&gt;
&lt;p&gt;0.13 introduces a new low-level API called &lt;code&gt;interrupt&lt;/code&gt; and a new option &lt;code&gt;interrupt-on-timeout&lt;/code&gt;. This is backend by a new protocol level command, &lt;code&gt;interrupt&lt;/code&gt;. The new command allows the client to interrupt server execution for a particular task. The server thread will be released once &lt;code&gt;interrupt&lt;/code&gt; received.&lt;/p&gt;
&lt;p&gt;Typically you don't have to call &lt;code&gt;interrupt&lt;/code&gt; on slacker client. The &lt;code&gt;interrupt-on-timeout&lt;/code&gt; option allows you to cancel a tasks on both client and server when it's timeout. Following the design principle of transparency, the cancellation is synchronized to server-side, just like a local invocation.&lt;/p&gt;
&lt;h3&gt;Plug-able Serializers&lt;/h3&gt;
&lt;p&gt;To keep our dependency-tree clean, we detects cheshire/nippy/carbonite at runtime, and makes these dependencies totally optional to slacker.&lt;/p&gt;
&lt;p&gt;The new default serializer is Clojure EDN because it requires no additional packages. Slacker provides built-in support for cheshire(&lt;code&gt;:json&lt;/code&gt;) and nippy(&lt;code&gt;:nippy&lt;/code&gt;). &lt;a href="https://github.com/ptaoussanis/nippy"&gt;Nippy&lt;/a&gt; is high recommended for Slacker. It's a clojure-native binary format, compact and fast. We have been using nippy with Slacker in our production for a long time without any issue.&lt;/p&gt;
&lt;p&gt;You can also extend our serializer system by create new implementations for serializer multi-method.&lt;/p&gt;
&lt;h3&gt;Server data for Slacker Cluster&lt;/h3&gt;
&lt;p&gt;The new Slacker Cluster &lt;code&gt;start-slacker-server&lt;/code&gt; offers a new option &lt;code&gt;:server-data&lt;/code&gt;. It allows you to assign some data for this server, for example, the environment (production or stage?). The data will be stored to Zookeeper and synchronized to client side.&lt;/p&gt;
&lt;p&gt;In the client grouping function, you can use the data to filter servers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;slacker.client.cluster&lt;/span&gt; &lt;span class="ss"&gt;:refer&lt;/span&gt; &lt;span class="ss"&gt;:all&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;sc&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;clustered-slackerc&lt;/span&gt; &lt;span class="nv"&gt;...&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;defn-remote&lt;/span&gt; &lt;span class="nv"&gt;sc&lt;/span&gt; &lt;span class="nv"&gt;some-function&lt;/span&gt;
  &lt;span class="ss"&gt;:grouping&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kd"&gt;ns &lt;/span&gt;&lt;span class="nv"&gt;func&lt;/span&gt; &lt;span class="nv"&gt;params&lt;/span&gt; &lt;span class="nv"&gt;servers&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
               &lt;span class="c1"&gt;;; test :prod? property of server data&lt;/span&gt;
               &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rand-nth&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;filter &lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:prod?&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;server-data&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="nv"&gt;sc&lt;/span&gt; &lt;span class="nv"&gt;%&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="nv"&gt;servers&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The grouping function in this snippet filters production servers, and choose one from them to call.&lt;/p&gt;
&lt;p&gt;The server side looks pretty simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;require&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;slacker.server.cluster&lt;/span&gt; &lt;span class="ss"&gt;:refer&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;start-slacker-server&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;start-slacker-server&lt;/span&gt; &lt;span class="nv"&gt;some-port&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;some-ns&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="ss"&gt;:server-data&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:prod?&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nv"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Besides of these features, we also fixed issues Zookeeper timeout issue on startup, ephemeral node lost and etc.&lt;/p&gt;
&lt;p&gt;After almost 4 years of development, we are stepping near to a 1.0 release. Hopefully we will reach the 1.0 milestone in 2016.&lt;/p&gt;</summary><category term="'programming'"></category><category term="'clojure'"></category></entry><entry><title>Running Ring web application on HTTP2 with rj9a</title><link href="https://sunng.info/blog/running-ring-web-application-on-http2-with-rj9a.html" rel="alternate"></link><updated>2015-07-25T14:54:54+08:00</updated><author><name>Ning Sun</name></author><id>tag:sunng.info,2015-07-25:blog/running-ring-web-application-on-http2-with-rj9a.html</id><summary type="html">&lt;p&gt;&lt;a href="https://github.com/sunng87/ring-jetty9-adapter"&gt;Ring-jetty9-adapter(rj9a)&lt;/a&gt; just received an update, the &lt;a href="https://clojars.org/info.sunng/ring-jetty9-adapter"&gt;0.9&lt;/a&gt;, with Jetty 9.3 adoption. The most important feature in this release is support for HTTP2. That means, you can run your Ring application on the new HTTP2 protocol.&lt;/p&gt;
&lt;p&gt;In case you still have no idea about HTTP2, it's the biggest update to HTTP, the protocol we use everyday and everywhere. In short, &lt;a href="https://en.wikipedia.org/wiki/HTTP/2"&gt;HTTP2&lt;/a&gt; introduces connection multiplex to reuse connection for several request/response simultaneously. Also the persisted connection makes server push possible, and that's part of HTTP2. HTTP2 uses TLS by default. In order to keep most servers backward compatible, we will run HTTP2 and HTTP1.1 on the same server and port. Modern client will detect server configuration on SSL handshake, via a TLS extension called ALPN. The server will list supported application layer protocols in SERVER HELLO and let client to choose what it understands.&lt;/p&gt;
&lt;p&gt;The basic part of HTTP2 is fully compatible for 1.1, so you won't have to modify your application code to use it. In rj9a, just add option &lt;code&gt;:h2? true&lt;/code&gt; to enable HTTP2. And &lt;code&gt;:h2c? true&lt;/code&gt; to enable its variance on plain socket.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;dummy-app&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;req&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:body&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;It works&amp;quot;&lt;/span&gt; &lt;span class="ss"&gt;:status&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;jetty/run-jetty&lt;/span&gt; &lt;span class="nv"&gt;dummy-app&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:port&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;
                            &lt;span class="ss"&gt;:h2c?&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
                            &lt;span class="ss"&gt;:h2?&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
                            &lt;span class="ss"&gt;:ssl?&lt;/span&gt; &lt;span class="nv"&gt;true&lt;/span&gt;
                            &lt;span class="ss"&gt;:ssl-port&lt;/span&gt; &lt;span class="mi"&gt;5443&lt;/span&gt;
                            &lt;span class="ss"&gt;:keystore&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;
                            &lt;span class="ss"&gt;:key-password&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To test HTTP2 interface, you will need to install &lt;a href="https://nghttp2.org"&gt;nghttp&lt;/a&gt;. It's pretty similar to curl:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ nghttp -v https://localhost:5443
&lt;span class="o"&gt;[&lt;/span&gt;  0.000&lt;span class="o"&gt;]&lt;/span&gt; Connected
The negotiated protocol: h2-14
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send SETTINGS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;12, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;niv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;2&lt;span class="o"&gt;)&lt;/span&gt;
         &lt;span class="o"&gt;[&lt;/span&gt;SETTINGS_MAX_CONCURRENT_STREAMS&lt;span class="o"&gt;(&lt;/span&gt;0x03&lt;span class="o"&gt;)&lt;/span&gt;:100&lt;span class="o"&gt;]&lt;/span&gt;
         &lt;span class="o"&gt;[&lt;/span&gt;SETTINGS_INITIAL_WINDOW_SIZE&lt;span class="o"&gt;(&lt;/span&gt;0x04&lt;span class="o"&gt;)&lt;/span&gt;:65535&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send PRIORITY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;3&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;201, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send PRIORITY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;101, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send PRIORITY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;7&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send PRIORITY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;9&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;7, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send PRIORITY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;11&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;3, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.031&lt;span class="o"&gt;]&lt;/span&gt; send HEADERS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;37, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x25, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;13&amp;gt;
         &lt;span class="p"&gt;;&lt;/span&gt; END_STREAM &lt;span class="p"&gt;|&lt;/span&gt; END_HEADERS &lt;span class="p"&gt;|&lt;/span&gt; PRIORITY
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;padlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;dep_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;11, &lt;span class="nv"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;16, &lt;span class="nv"&gt;exclusive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
         &lt;span class="p"&gt;;&lt;/span&gt; Open new stream
         :method: GET
         :path: /
         :scheme: https
         :authority: localhost:5443
         accept: */*
         accept-encoding: gzip, deflate
         user-agent: nghttp2/1.0.1
&lt;span class="o"&gt;[&lt;/span&gt;  0.032&lt;span class="o"&gt;]&lt;/span&gt; recv SETTINGS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;12, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;niv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;2&lt;span class="o"&gt;)&lt;/span&gt;
         &lt;span class="o"&gt;[&lt;/span&gt;SETTINGS_HEADER_TABLE_SIZE&lt;span class="o"&gt;(&lt;/span&gt;0x01&lt;span class="o"&gt;)&lt;/span&gt;:4096&lt;span class="o"&gt;]&lt;/span&gt;
         &lt;span class="o"&gt;[&lt;/span&gt;SETTINGS_INITIAL_WINDOW_SIZE&lt;span class="o"&gt;(&lt;/span&gt;0x04&lt;span class="o"&gt;)&lt;/span&gt;:65535&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.032&lt;span class="o"&gt;]&lt;/span&gt; send SETTINGS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x01, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&amp;gt;
         &lt;span class="p"&gt;;&lt;/span&gt; ACK
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;niv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.032&lt;span class="o"&gt;]&lt;/span&gt; recv SETTINGS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x01, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&amp;gt;
         &lt;span class="p"&gt;;&lt;/span&gt; ACK
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;niv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.033&lt;span class="o"&gt;]&lt;/span&gt; recv &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;13&lt;span class="o"&gt;)&lt;/span&gt; :status: 200
&lt;span class="o"&gt;[&lt;/span&gt;  0.033&lt;span class="o"&gt;]&lt;/span&gt; recv &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;13&lt;span class="o"&gt;)&lt;/span&gt; server: Jetty&lt;span class="o"&gt;(&lt;/span&gt;9.3.1.v20150714&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;  0.033&lt;span class="o"&gt;]&lt;/span&gt; recv HEADERS frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;20, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x04, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;13&amp;gt;
         &lt;span class="p"&gt;;&lt;/span&gt; END_HEADERS
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;padlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&lt;span class="o"&gt;)&lt;/span&gt;
         &lt;span class="p"&gt;;&lt;/span&gt; First response header
It works&lt;span class="o"&gt;[&lt;/span&gt;  0.033&lt;span class="o"&gt;]&lt;/span&gt; recv DATA frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;8, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x01, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;13&amp;gt;
         &lt;span class="p"&gt;;&lt;/span&gt; END_STREAM
&lt;span class="o"&gt;[&lt;/span&gt;  0.033&lt;span class="o"&gt;]&lt;/span&gt; send GOAWAY frame &amp;lt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;8, &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0x00, &lt;span class="nv"&gt;stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0&amp;gt;
         &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;last_stream_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0, &lt;span class="nv"&gt;error_code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;NO_ERROR&lt;span class="o"&gt;(&lt;/span&gt;0x00&lt;span class="o"&gt;)&lt;/span&gt;, opaque_data&lt;span class="o"&gt;(&lt;/span&gt;0&lt;span class="o"&gt;)=[])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The verbose output shows us every detail about request and response in HTTP2.&lt;/p&gt;
&lt;p&gt;Note that in order to run HTTP2, you will need JDK 8 / OpenJDK 1.8 and &lt;a href="http://www.eclipse.org/jetty/documentation/current/alpn-chapter.html#alpn-starting"&gt;put alpn-boot jar in your bootclasspath&lt;/a&gt;.  I have created &lt;a href="https://github.com/sunng87/lein-bootclasspath-deps"&gt;a leiningen plugin&lt;/a&gt; to manage bootclasspath in clojure project.&lt;/p&gt;
&lt;p&gt;The complete example is available in &lt;a href="https://github.com/sunng87/ring-jetty9-adapter/blob/master/examples/rj9a/http2.clj"&gt;github repository&lt;/a&gt;.&lt;/p&gt;</summary><category term="'programming'"></category><category term="'clojure'"></category></entry><entry><title>"Handlebars 的 rust 实现"</title><link href="https://sunng.info/blog/handlebars-de-rust-shi-xian.html" rel="alternate"></link><updated>2015-01-25T16:22:50+08:00</updated><author><name>Ning Sun</name></author><id>tag:sunng.info,2015-01-25:blog/handlebars-de-rust-shi-xian.html</id><summary type="html">&lt;p&gt;本来一度感觉到用过 Clojure 之后很难对新语言产生兴趣了，还好遇到了 Rust 再次激活了这方面的生命力。今年的重点之一是学习 Rust 语言，方便自己能真正 touch bare metal。1月17号的 Rust 聚会上发现很多人都持有类似的想法。 C++ 之后鲜有这种语言，以至于之后成长起来的一代人都是在一个 VM 里编程，无论是 Java 还是 Python，最终都没有办法自己去管理内存，Rust 的出现给了大家一个机会。一个具备现代特性的系统编程语言，Zero runtime，可以运行在各种设备上。去年还给&lt;a href="http://sunng.info/blog/blog/2014/04/20/rust-concurrent-made-safely/"&gt;程序员杂志写了一篇 Rust 的文章&lt;/a&gt;，结果导致现在程序员杂志停刊了。&lt;/p&gt;
&lt;p&gt;扯远了，和当时学 Clojure 一样，这次的计划还是写一个正经的项目来促进学习。关于时机的选择，主要是 crates.io 仓库的发布基本上标志生态圈开始建立了，这个时候写东西就方便很多了。&lt;/p&gt;
&lt;p&gt;这次选的就是实现 Handlebars，主要原因是 rust 已经逐渐有一点 web 开发的生态圈了，但是缺少一个模版引擎，于是我就来趟这潭浑水吧。为什么是 Handlebars 呢：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不要把 rust 代码写进 html 模版里，反例： jsp, ejs&lt;/li&gt;
&lt;li&gt;不要把 html 代码写进 rust 里，反例： hiccup&lt;/li&gt;
&lt;li&gt;能够复用，基于“继承”而不是 include&lt;/li&gt;
&lt;li&gt;能够简单地自定义标签，反例：mustach&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于以上的原则，&lt;a href="https://github.com/sunng87/handlebars-rust"&gt;handlebars-rust&lt;/a&gt; 实现了基本的模版解析、渲染，重用机制（partial/include）和自定义 helper。除了不支持一些 mustach 风格的语法以外（可以用 #each / #if 这样的 helper 替代，更清晰），基本上所有的 handlebars 功能全部支持了。如果有遗漏的话欢迎 PR。另外还写了一个 &lt;a href="https://github.com/sunng87/handlebars-iron"&gt;handlebars-iron&lt;/a&gt; 项目，作为一个 &lt;a href="http://ironframework.io"&gt;Iron 框架&lt;/a&gt;的 middlaware。&lt;/p&gt;
&lt;p&gt;简单总结几点收获：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rust 中要实现类似OO的多态需要用枚举类型，trait可以用来做范型&lt;/li&gt;
&lt;li&gt;静态类型语言和一个基于 javascript 视角的模版引擎对接很困难，比如 js 里有 falsy 的概念，if 的判断里 &lt;code&gt;false&lt;/code&gt;/&lt;code&gt;0&lt;/code&gt;/&lt;code&gt;""&lt;/code&gt;/&lt;code&gt;[]&lt;/code&gt; 这些值都是 false，但是在rust里需要根据不同类型作判断，直接使用简直不可能。所以在 handlebars-rust 里利用了 rustc-serialize 里的 &lt;code&gt;Json&lt;/code&gt; 枚举类型（没有真正序列化），要求所有渲染的数据都必须实现 &lt;code&gt;ToJson&lt;/code&gt;，算是设计上的一个取舍。&lt;/li&gt;
&lt;li&gt;Rust 的 derive 是一个神奇的功能，后来发现确实是一个 magic，因为可以 derive 的 trait 都是写死在编译器里的&lt;/li&gt;
&lt;li&gt;关于 Rust 的 ownership 看&lt;a href="http://nercury.github.io/rust/guide/2015/01/19/ownership.html"&gt;这篇文章&lt;/a&gt;，作者承诺再写一篇关于 borrow 和 lifetime 的，相信也不错&lt;/li&gt;
&lt;li&gt;有任何问题都可以在 stackoverflow 上问，有几个人会很快回复&lt;/li&gt;
&lt;/ul&gt;</summary><category term="'programming'"></category><category term="'rust'"></category></entry><entry><title>"AVOS Cloud 实时通信服务架构：微服务和服务发现"</title><link href="https://sunng.info/blog/avos-cloud-shi-shi-tong-xin-fu-wu-jia-gou-wei-fu-wu-he-fu-wu-fa-xian.html" rel="alternate"></link><updated>2014-08-19T16:46:20+08:00</updated><author><name>Ning Sun</name></author><id>tag:sunng.info,2014-08-19:blog/avos-cloud-shi-shi-tong-xin-fu-wu-jia-gou-wei-fu-wu-he-fu-wu-fa-xian.html</id><summary type="html">&lt;p&gt;“微服务” (Microservice) 是今年特别热的一个概念，&lt;a href="http://martinfowler.com/articles/microservices.html"&gt;Martin Fowler 的文章&lt;/a&gt;对微服务作了详细的介绍。简而言之，微服务鼓励用户把功能拆分以细粒度的服务接口暴露出来，并通过REST 服务或轻量级消息队列集成。在微服务架构里，一个业务的实现，可能由不同的功能单元组合而实现。&lt;/p&gt;
&lt;p&gt;在 AVOS Cloud，我们提供数据存储、统计、实时通信等不同功能的服务，在实现上，这些功能需要共用基础设施，有的服务本身也根据业务性质的不同拆分功能模块，我们目前就是以这种“微服务”架构思路来实现拆分。有句话说，if you cannot split, you cannot scale.&lt;/p&gt;
&lt;p&gt;以实时通信服务为例，根据功能角色的不同，我们有这样一些模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Push 服务：处理推送的订阅关系，触发推送&lt;/li&gt;
&lt;li&gt;长连接服务器：维持设备与服务的长连接&lt;/li&gt;
&lt;li&gt;Router：应用层的 lookup，负责分配合适的长连接服务器给新设备&lt;/li&gt;
&lt;li&gt;WatchDog：从多台长连接服务器收集运行和统计数据，对异常情况发起报警&lt;/li&gt;
&lt;li&gt;数据存储：群组数据，用户可以通过API访问&lt;/li&gt;
&lt;li&gt;HBase：消息记录存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;模块间的集成，根据业务的特性分别使用 &lt;a href="https://github.com/sunng87/slacker"&gt;Slacker&lt;/a&gt; 远程调用框架和 &lt;a href="http://twitter.github.io/kestrel/"&gt;Kestrel&lt;/a&gt; 消息队列。
对于可能耗时较大的任务，我们通过 Kestrel 队列放到后台执行，避免阻塞前台服务，影响吞吐量。而另一些需要实时的集成，则使用 Slacker 远程调用实现多个进程间的通信。&lt;/p&gt;
&lt;p&gt;Slacker 是一个专门为 Clojure 语言设计的远程调用框架，利用 Slacker 你可以暴露一个 或多个 Clojure 的 namespace 供远程调用。在客户端，Slacker 利用 &lt;a href="http://clojure.org/macros"&gt;Clojure 宏&lt;/a&gt;的特性，保持远程调用和本地调用的代码完全一致，这样本地和远程调用的切换只要更改一个 &lt;code&gt;(require)&lt;/code&gt; 即可实现，把框架对业务代码的侵入降到最低。此外，Slacker 使用二进制序列化 &lt;a href="https://github.com/ptaoussanis/nippy"&gt;nippy&lt;/a&gt;，在网络连接层面使用异步复用，同时在超时方面也做了良好的控制。&lt;/p&gt;
&lt;p&gt;以上的基础设施帮助我们良好地拆分模块，为下一步的扩展提供了可能。&lt;/p&gt;
&lt;h3&gt;服务发现&lt;/h3&gt;
&lt;p&gt;长连接服务器是实时通信的功能核心，它的瓶颈在内存和 CPU，可以通过增加部署来达到线性扩展。随着业务量的增加和硬件资源的整合，它可能会面临较频繁的部署变化，另外它也需要有能通过新增部署来快速平滑高峰压力的能力。基于 &lt;a href="https://en.wikipedia.org/wiki/Publish/subscribe"&gt;Pub/Sub 抽象&lt;/a&gt;的消息队列对此有良好的支持，但这对我们以 RPC 为核心的集成方式提出了新的要求，依赖模块也能快速响应服务部署的变化：我们不可能在新增某个服务部署后修改每个依赖的配置再逐一重启。&lt;/p&gt;
&lt;p&gt;在这方面，我们利用了 &lt;a href="https://github.com/sunng87/slacker-cluster"&gt;Slacker Cluster 框架&lt;/a&gt;。他的核心思想是在部署和服务间增加一层抽象：对于服务的消费者而言，只需声明自己所依赖的服务，而无需静态地了解进程的地址。&lt;/p&gt;
&lt;p&gt;所有的服务提供者将自己能够提供的服务注册在 &lt;a href="https://zookeeper.apache.org/"&gt;Zookeeper&lt;/a&gt; 集群里，并将部署地址注册为 Ephemeral 节点。Ephemeral 节点在创建它的连接断后会自动删除，这样当一个部署下线后，它相应的节点也会自动删除。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Zookeeper 目录结构&lt;/span&gt;
ls /slacker/example-cluster/namespaces/
&lt;span class="o"&gt;[&lt;/span&gt;my.serviceA, my.serviceB&lt;span class="o"&gt;]&lt;/span&gt;

ls /slacker/example-cluster/namespaces/my.serviceA
&lt;span class="o"&gt;[&lt;/span&gt;192.168.1.100:2104, 192.168.1.101:2014...&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;所有服务的客户端会 watch 自己感兴趣的 Zookeeper 节点，而部署变化时，所有的客户端都会得到通知，进而刷新服务列表，将流量引向新的节点。&lt;/p&gt;
&lt;p&gt;在实时通信服务中，Router 服务会通过这个 RPC 机制轮询所有在线的长连接服务器，记录他们实时的运行状态。所有的用户设备并非直接连接到固定的长连接服务器，而是先询问 Router，由后者分配一台压力较轻的实例。当有新的长连接服务器部署后，Router收到通知，新的连接将优先连接这个新进程。此外，监控和数据收集的服务也会自动地把新实例加入管理范围。&lt;/p&gt;
&lt;p&gt;有了这样一套服务发现机制，我们就可以对整个架构中的任意模块随时增减部署，保证服务可以以健康的状态运行。未来，我们还会集成云主机的提供商的API，来实现基础设施的自动化：当系统压力达到阀值时，云主机自动分配新的资源自动开机，jenkins 自动部署，加上现有的服务发现机制，实现0手工操作。这将是云服务运维的新篇。&lt;/p&gt;
&lt;p&gt;原载 &lt;a href="https://blog.avoscloud.com/1927/"&gt;AVOSCloud Blog&lt;/a&gt;&lt;/p&gt;</summary><category term="programming"></category></entry></feed>