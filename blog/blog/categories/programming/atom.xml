<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | Here comes the Sun]]></title>
  <link href="http://sunng87.github.io/blog//blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://sunng87.github.io/blog//"/>
  <updated>2014-06-09T22:43:55+08:00</updated>
  <id>http://sunng87.github.io/blog//</id>
  <author>
    <name><![CDATA[Sun Ning]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Slacker Cluster 0.12: Grouping]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12/"/>
    <updated>2014-06-09T21:06:39+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12</id>
    <content type="html"><![CDATA[<h2>What are Slacker and Slacker Cluster</h2>

<p><a href="https://github.com/sunng87/slacker">Slacker</a> is my side project started in late 2011. The goal of Slacker project is to provide a high performance RPC system for clojure, with elegant API. Slacker doesn&rsquo;t ruin your code. Your remote invocation looks exactly same as local, from code. That means you can switch back and forth at same time.</p>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> is a support module for running Slacker servers with multiple instances. Cluster enabled slacker server will publish all its served namespaces to Zookeeper cluster. The Cluster enabled client reads and watches these meta data. The most important feature of Slacker Cluster is you can add or remove servers without changing client configuration.</p>

<h2>Grouping in Slacker Cluster</h2>

<p>Started in 0.11, then enhanced in 0.12, Slacker Cluster now has flexible <strong>grouping</strong> choices for your scenario. In Slacker Cluster, <strong>grouping</strong> means which server(s) to call on a particular invocation.</p>

<p>There and four kinds of grouping for you: <code>:random</code>, <code>:leader</code>, <code>:all</code> and custom.</p>

<h3>:random</h3>

<p>By default, Slacker cluster clients use <code>:random</code> grouping: select a random server from server list. Random grouping works great for stateless services. It automatically balances load of each server.</p>

<h3>:leader</h3>

<p>Slacker servers selects leader for each namespace they expose. So at any time there will be one and only one leader node for every namespaces. The <code>:leader</code> grouping routes all invocations onto the leader node. This is required when your server has state, and you have to ensure the consistency and availability.</p>

<h3>:all</h3>

<p>As the name suggests, <code>:all</code> grouping routes invocations on every node at same time. In other words, it&rsquo;s broadcast. Note that this grouping might change your function return values. In <code>:random</code> and <code>:leader</code> mode, there&rsquo;s only one server called, just like local invocation. In <code>:all</code>, there&rsquo;s chances several servers are called and several values returned. I will talk about how to deal with these return values later.</p>

<h3>Custom</h3>

<p>You can also provide a function for dynamic grouping. For requested namespace, function and arguments, you can specify any server(s) or grouping option.</p>

<h2>Grouping results</h2>

<p>Grouping may break original behavior of you code by returning multiple values from multiple servers. But you still have full control over it. There are four types of value you can specify for results aggregation: <code>:single</code>, <code>:vector</code>, <code>:map</code> and custom function.</p>

<p>In short words:</p>

<ul>
<li><code>:single</code> returns the first valid result, and behavior same as calling single server or local invocation. This is the default value.</li>
<li><code>:vector</code> returns  a vector of all results.</li>
<li><code>:map</code> returns a map of all results, indexed by server addresses.</li>
<li>Custom aggregation function accepts the results and allows you to merge the values.</li>
</ul>


<h2>Grouping exceptions</h2>

<p>What happens when remote function threw exceptions? The grouping exception option defines that. When set to <code>:all</code>, the client will raise an error only if all remote nodes broken. Otherwise, the broken result will be ignored and only valid results will apply <code>grouping-results</code> rules. The opposite option is <code>:any</code>, which mean client will raise error when any of calls is broken.</p>

<h2>Granularity</h2>

<p>The grouping options can be set to client level:</p>

<p><code>clojure
(clustered-slackerc "cluster-name" "127.0.0.1:2181" :grouping :leader)
</code></p>

<p>or function level:</p>

<p><code>clojure
(defn-remote sc slacker.example.api/timestamp
  :grouping :all
  :grouping-results :single)
</code></p>

<h2>Conclusion</h2>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> has been used in our Avos Cloud backend for service integration. Feel free to let me know if you have interests or questions with this library.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fork-Join in Papaline]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline/"/>
    <updated>2014-05-27T21:47:45+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline</id>
    <content type="html"><![CDATA[<p><a href="http://github.com/sunng87/papaline">Papaline</a> 0.3 introduced a new model &ldquo;fork-join&rdquo; for task execution. It allows you to split a task into smaller units, and execute them in parallel.</p>

<p>Before that, a task is processed as a single unit from the first stage to the second, the third and the last. Within a stage, all computing is done in a single thread.</p>

<p><img src="http://i.imgur.com/w6RlNZo.png" alt="linear execution" /></p>

<p>This model has limitation that you are required to execute any of your stage in serial. If your task has a few split-able units, it&rsquo;s always better to run them in parallel. Here we have <code>(fork)</code> command for the situation.</p>

<p>For example, you are using the <em>fanout-on-write</em> model to build an activity stream. Once a user posted a new status, you need to find all followers(stage 1) of that user and append the status to their timeline(stage 2).</p>

<p>In previous version of papaline, these two stages are:</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>[followers msg]))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (doseq [user-id user-ids]</p>

<pre><code>(write-redis-list user-id msg)))
</code></pre>

<p>```</p>

<p>In the second task, the msg is appended to user&rsquo;s timeline one by one.</p>

<p>Using <code>(fork)</code>, the <code>fanout-to-user-timeline</code> can be executed in parallel.</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>(fork (map #(vector % msg) followers))))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (write-redis-list user-id msg))</p>

<p>```</p>

<p>After the <code>find-followers</code> function, the result will be splitted into <code>(count followers)</code> parts and sent into input channel of stage 2. So the tasks execution will be like:</p>

<p><img src="http://i.imgur.com/MLhZ0Pm.png" alt="forked execution" /></p>

<p>To collect the results of all forked sub-tasks, you can use <code>(join)</code>. If the return value is wrapped with join, it won&rsquo;t trigger next stage immediately but to wait all forked tasks to finish.</p>

<p><img src="http://i.imgur.com/BVDEH9Q.png" alt="join" /></p>

<p>So with <code>(fork)</code> and <code>(join)</code>, it&rsquo;s very flexible to change execution model in Papaline.  Internally, I use clojure&rsquo;s <a href="http://clojure.org/metadata">metadata</a> to add flags for the return value, without ruining the non-invasive design of <a href="http://github.com/sunng87/papaline">Papaline</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Papaline: Concurrent Pipeline With core.async]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/04/20/concurrent-pipeline-with-core-async/"/>
    <updated>2014-04-20T17:21:44+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/04/20/concurrent-pipeline-with-core-async</id>
    <content type="html"><![CDATA[<p>According to <a href="http://en.wikipedia.org/wiki/Staged_event-driven_architecture">wikipedia</a>, Staged Event-driven Architecture is an approach to software architecture that decomposes a complex, event-driven application into a set of stages connected by queues. We were using Java framework, <a href="https://github.com/sunng87/stages">stages</a>, to implement queue based SEDA. As we are using more and more Clojure nowadays, I decide to re-implement it in Clojure language, and in Clojure way. It&rsquo;s <a href="https://github.com/sunng87/papaline">papaline</a>.</p>

<p>The most important difference between papaline and stages is the usage of IoC threads. Core.async introduces IoC threads for Clojure, which is a popular concurrent mechanism recently. In traditional queue based thread pool, threads are blocked on queue to wait for tasks. While for IoC threads, channels act similar to queues but no actual thread is blocked on channel. Once there is a task available in channel, an underlying thread will be picked to execute it. So for core.async, you don&rsquo;t have to assign a static thread pool to each channel. The channel will pick thread from a shared system thread pool on demand. In current core.async release, it&rsquo;s a fixed thread pool with <em>(processors * 4) + 42</em> threads. That&rsquo;s much flexible and efficient.</p>

<p>Papaline takes advantages of this feature. The base concept in papaline is <strong>stage</strong> and <strong>pipeline</strong>. A pipeline is created with a ordered sequence of stages. Stages configured in a pipeline are connected with channels, instead of queues. Threads are automatically managed by core.async, and scheduled based on load of channels.</p>

<p>When you run a pipeline, the input data is sent to the inbound channel of the first stage. The stage will received the data and pick a thread to execute the function. Then the result is put into the second stage&rsquo;s inbound channel. The user-visible behavior is much like <code>comp</code>, but in concurrent.</p>

<p>Also core.async offers different type of channel buffers: fixed <code>buffer</code>, <code>sliding-buffer</code> and <code>dropping-buffer</code>. They are channels equivalent to j.u.c thread pool&rsquo;s <code>RejectedExecutionHandler</code>.</p>

<p>We have already deployed papaline in our asynchronous system and it works great by far. Find the project on <a href="https://github.com/sunng87/papaline">github</a> if you are interested in.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust语言：安全的并发]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/04/20/rust-concurrent-made-safely/"/>
    <updated>2014-04-20T16:31:54+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/04/20/rust-concurrent-made-safely</id>
    <content type="html"><![CDATA[<p>本文原载于2014年3月《程序员》杂志编程语言专题。</p>

<p>Rust 语言是近两年来 Mozilla 正在开发的一种新编程语言，它以并发，安全和实用为口号，主要使用场景是系统编程，用来取代C++语言的角色。有人戏称 Mozilla 由于大量使用 C++，深知其弊端，所以诞生了 Rust。目前，Rust 的两个主要产品是 Mozilla 下一代的浏览器布局引擎 Servo 和 Rust 编译器。由于语言在快速的开发和演进中，每个版本都会产生一些不兼容的变更，所以现在并非是学习这门语言细节并真正使用它的最佳时机。不过，这并不影响我们了解 Rust 语言：作为多年来鲜有的新系统编程语言，他本身有很多新颖之处，也可以帮助我们了解一些编程语言设计的流行趋势。</p>

<h2>并发</h2>

<p>和现在流行的很多新语言一样，Rust 在语言层面支持了绿色线程（Green threads）：Task。Task 作为并发执行的单元，是用户空间的“线程”，创建和调度成本较低，可以大量共存。Task之间通过消息传递通信，没有直接的共享数据。从最近的流行趋势来看，绿色线程几乎已经成为并发方案大战最终的赢家。除了Rust，之前流行的Go语言，Erlang，Python的Gevent，以及最近Clojure世界里正在发展的core.async，采用的都是这种绿色线程的模式。</p>

<p>绿色线程的程序与传统多线程程序的写法几乎一致。在编写服务器程序时，与事件驱动的回调机制相比，编写更简单，表义更清晰。当并发任务增多时，传统的多线程程序由于启动线程和调度线程的成本高而使系统整体性能降低。而绿色线程可以基本不受限制，随意创建。Rust的文档指出在32位系统上可以支持数十万个Task同时存在。</p>

<p>Task也是Rust程序的基础单元，一个Rust进程又多个并行的task组成，main函数本身也是一个Task。Task之间通过一个 (Port, Chan) 元组传递数据。Port和Chan相当于管道的两端，Port用于取数据，Chan用于发送数据。下面的例子里，我们通过do spawn语法（类似Ruby的block语法），启动一个新Task，并打印收到的数据。</p>

<p>``` rust
fn main(){
  let msg = &ldquo;hello world&rdquo;;
  let (port, chan) = Chan::new();</p>

<p>  chan.send(msg);</p>

<p>  do spawn {</p>

<pre><code>let received_msg = port.recv(); 
println(received_msg); 
</code></pre>

<p>  }
}</p>

<p>```</p>

<h2>引用系统</h2>

<p>Rust 语言设计的核心是安全性（这里安全性指safety，而非 security）。Rust 希望通过语言的机制和编译器的功能，把程序员易于犯错，不易检查的问题解决在编译期，避免运行时的Segmentation Fault。Rust 的设计可以说是处处小心。Clojure语言强调可变性给编程带来的复杂性，在 Rust 语言中，设计者对这点也有格外的重视。除非特别声明为 mut，所有 Rust 的局部变量默认都是不可变的，对不可变变量值的修改会导致 编译器直接报错。</p>

<p>Rust 的安全性还通过独有的引用类型系统来实现。</p>

<p>Rust 语言中堆内存块的引用类型叫做box。最新版本的Rust 在语言层面只保留了一种owned box，它在使用时具有一种所有权（ownership）的概念，只有具有所有权的变量才可以访问这段内存。Owned box在同一时刻只允许一个变量作为所有者，它的变量赋值称为move。一旦owned pointer被赋值，用户就无法通过原先的引用访问这块数据，这种错误会在编译时检查。
一个简单的例子：</p>

<p>``` rust
fn main() {</p>

<pre><code>let a: ~int = ~50;
let b: ~int = a;
println!("{:?}", *a);
</code></pre>

<p>}
```</p>

<p>~ 代表owned box，这里我们把一个包含值为50的owned box赋给owned pointer a。然后把a的所有权通过赋值的形式move给b。最后我们试图通过 <code>*a</code> 访问这个值。在C语言里，这时a和b同时指向统一块内存，可以通过<code>*a</code>访问到这里的值。但Rust的所有权机制给予了这段内存额外的保护。编译这段程序将失败：</p>

<p><code>``
own.rs:4:23: 4:24 error: use of moved value:</code>a`
own.rs:4     println!(&ldquo;{:?}&rdquo;, *a);</p>

<pre><code>                           ^
</code></pre>

<p>&hellip;
own.rs:3:9: 3:10 note: <code>a</code> moved here because it has type <code>~int</code>, which is moved by default (use <code>ref</code> to override)
own.rs:3     let b: ~int = a;</p>

<pre><code>             ^
</code></pre>

<p>```
编译器会明确地指出错误的引用在何处被move。事实上所有owned box的生命周期管理都是直接在编译时完成的，编译器通过静态检查跟踪使用情况，完成内存开辟和回收。这是Rust 确保编程正确、安全的重要手段。</p>

<p>新版本的Rust在标准库中提供 <code>std::rc::Rc</code>（引用计数） 和 <code>std::gc::Gc</code> （垃圾回收）类型，取代了原先的managed box，用来提供可以有限共享的引用类型。</p>

<p>在 Task 间传递数据，如果要避免数据拷贝，也有专门的引用类型：用于不可变数据的<code>extra::arc::Arc</code> (atomically reference counted ，原子的引用计数类型) , 以及用于可变数据的 RWArc（带读写锁的原子引用计数类型） 。RWArc在操作可变数据时，通过内在的读写锁控制对共享数据的访问，从而在API层面实现安全性。</p>

<p>``` rust
extern mod extra;
use extra::arc::{RWArc};</p>

<p>fn main() {</p>

<pre><code>let s = ~"hello world";
let arc_ref = RWArc::new(s);

for i in range(0, 10) {
    let (port, chan) = Chan::new();
    chan.send(arc_ref.clone());

    do spawn {
        let arc_local_ref = port.recv();

        arc_local_ref.write(|str| {
            str.push_char('!');
        });

        arc_local_ref.read(|str| {
            println(*str);
        });
    }
}
</code></pre>

<p>}
```</p>

<p>Rust谨慎地定义如此繁多，各具功能的引用类型，就是希望用户在编程过程中，根据应用场景、引用的功能职责，选择合适的类型，进而在引用类型系统和编译器的保护下，减少在运行时出错的机会。这一点也和Clojure的4种引用类型的设计初衷类似，不过Clojure并不能提供太多编译时的安全保护。</p>

<h2>更多</h2>

<p>篇幅所限，我只选择了Rust最具特点的两个部分介绍。Rust是一门具备自身显著特点，精心设计的语言，而绝非普通的“又一门编程语言”。在语法层面，它包含了模式匹配，闭包，泛型等流行功能，作为系统编程语言，使用的舒适度不亚于脚本语言。另外还可以通过FFI（Foreign Function Interface）调用已有的C语言库，满足了实用性的需要。</p>

<p>如果你也开始对这门新语言感兴趣，可以：</p>

<ul>
<li>通过<a href="http://static.rust-lang.org/doc/master/tutorial.html">它的文档</a>学习最新版本的语法和细节</li>
<li>加入<a href="https://mail.mozilla.org/listinfo/rust-dev">rust-dev邮件列表</a>了解开发者的讨论</li>
<li>关注<a href="https://github.com/mozilla/rust">Rust项目代码仓库</a></li>
<li>关注<a href="https://delicious.com/tag/rust">Delicious</a> 和 <a href="http://www.reddit.com/r/rust">Reddit</a> 上流行的 rust 链接</li>
<li>关注<a href="http://cmr.github.io/">The week in Rust</a>，介绍每周 Rust 语言正在发生的变化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slacker Library Updated]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/03/04/slacker-0-dot-11-released/"/>
    <updated>2014-03-04T23:40:00+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/03/04/slacker-0-dot-11-released</id>
    <content type="html"><![CDATA[<p>After almost two years idle in commit log, I restarted development of my slacker frameworks recently. It will be used in our AVOS Cloud production as integration solution between clojure systems.</p>

<p>The recent update in slacker, slacker-cluster and link are:</p>

<h3>link</h3>

<p>There are two releases in the <a href="https://github.com/sunng87/link">link</a> library, features include:</p>

<ul>
<li>Ported to Netty 4</li>
<li>WebSocket server handler</li>
<li>Ability to shutdown server</li>
<li>Ability to use core.async with link ring adapter</li>
</ul>


<h3>slacker</h3>

<p>The most recent release of <a href="https://github.com/sunng87/slacker">slacker</a> is 0.11.0:</p>

<ul>
<li>New ping-interval option for clients</li>
<li>Async callback will accept two argument, and can handle exceptions</li>
<li>Slingshot removed, we are now using clojure built-in ex-info</li>
<li>All client creation functions and defn-remote are delayed</li>
<li>Bugfix for issue when several clients started in a process</li>
</ul>


<h3>slacker-cluster</h3>

<p>There&rsquo;s major enhancement in <a href="https://github.com/sunng87/slacker-cluster">slacker cluster</a> 0.11.0</p>

<ul>
<li>Server exception no longer blocks client</li>
<li>Added options to call functions on multiple servers, control return type and exception handling</li>
</ul>


<p>All these libraries are available on github. I will write more about how we use them in AVOS Cloud in future.</p>
]]></content>
  </entry>
  
</feed>
