<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | Here comes the Sun]]></title>
  <link href="http://sunng87.github.io/blog//blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://sunng87.github.io/blog//"/>
  <updated>2014-08-02T19:45:23+08:00</updated>
  <id>http://sunng87.github.io/blog//</id>
  <author>
    <name><![CDATA[Sun Ning]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[在 Docker 中安装和使用 Rust Nightly 版本]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/08/02/rust-with-docker/"/>
    <updated>2014-08-02T18:02:12+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/08/02/rust-with-docker</id>
    <content type="html"><![CDATA[<p>一直关注 Rust 语言，最近一下发现了两个 web 框架，<a href="http://ironframework.org">Iron</a> 和 <a href="http://nickel.rs">Nickel.rs</a>。先不说这两个框架成熟度如何，一般情况下，一个语言有了 web 框架，算是一个里程碑，说明他离靠谱也不远了。这样我决定跟一下 nightly 版本（新框架都是跟 nightly），另外也能感受一下 <a href="https://mail.mozilla.org/pipermail/rust-dev/2014-March/009090.html">Yehuda Katz 的构建工具 Cargo</a>。ArchLinux 的仓库里已经有 0.11 版本，再用脚本安装必然会有冲突。于是想到了最近半年<a href="https://twitter.com/jessenoller/status/495037475421954048">最火的 Docker</a>，可以轻松的创建多个环境，正是一个非常好的场景。</p>

<h2>安装</h2>

<p>安装 Docker, Arch Linux 仓库里很早就有，非常方便：<code>sudo pacman -S docker</code>。完成之后启动他：<code>sudo systemctl start docker</code>。</p>

<p>之后我们拉一个 ubuntu 的镜像下来：<code>docker pull ubuntu</code>。</p>

<p>完成之后，我们启动一个 container，做一些基本的 setup：<code>docker run -i -t ubuntu:14.04 /bin/bash</code></p>

<p>这相当与运行在 ubuntu:14.04 这个镜像上运行一个 shell，接下来就进入了这个 shell 环境，和 ubuntu 安装版本完全一致，我们做一些基础的准备，安装一些必要的工具：<code>apt-get install build-essentials git curl libssl-dev</code></p>

<p>之后，就可以下载 Rust 提供的脚本来安装 nightly 版本了：<code>curl -s http://www.rust-lang.org/rustup.sh &gt; rustup</code></p>

<p>这里有个问题，rustup 脚本判断64位系统时会出错导致安装失败：
```sh</p>

<h1>Detect 64 bit linux systems with 32 bit userland and force 32 bit compilation</h1>

<p>if [ $CFG_OSTYPE = unknown-linux-gnu -a $CFG_CPUTYPE = x86_64 ]
then</p>

<pre><code>file -L "$SHELL" | grep -q "x86[_-]64"
if [ $? != 0 ]; then
    CFG_CPUTYPE=i686
fi
</code></pre>

<p>fi
```</p>

<p>因为在我的机器上已知系统是64位，就强行绕过了他的判断。</p>

<p>```bash
if [ $CFG_OSTYPE = unknown-linux-gnu -a $CFG_CPUTYPE = x86_64 ]
then</p>

<pre><code>file -L "$SHELL" | grep -q "x86[_-]64"
if [ $? == 0 ]; then
    CFG_CPUTYPE=i686
fi
</code></pre>

<p>fi
```</p>

<p>之后执行 rustup 就可以直接安装最近的 rustc 和 cargo 了。安装完成执行 <code>rustc -v</code> 和 <code>cargo --version</code> （两个工具还不统一！）可以了解安装情况。</p>

<p>exit 退出 shell，commit 你的镜像，这样一个干净的镜像要好好保存：<code>docker commit IMAGE_ID sunng/rust-nightly</code></p>

<h2>Hello World</h2>

<p>之后可以写点代码了，我们不在 docker 里写，我们在 host 机器上写，然后挂载到 docker 上，因此 emacs 什么的也不用配置了。</p>

<p>创建一个目录，比如在 <code>$HOME/var/docker/helloworld</code>下，最简单的 rust 项目只要两个文件： <code>Cargo.toml</code> 和 <code>src/main.rs</code>。</p>

<p>```</p>

<h1>Cargo.toml</h1>

<p>[package]</p>

<p>name = &ldquo;hello-world&rdquo;
version = &ldquo;0.1.0&rdquo;
authors = [ &ldquo;<a href="&#109;&#x61;&#105;&#x6c;&#116;&#x6f;&#58;&#115;&#x75;&#x6e;&#110;&#103;&#x40;&#x61;&#98;&#111;&#x75;&#116;&#46;&#x6d;&#101;">&#x73;&#117;&#110;&#110;&#x67;&#64;&#97;&#98;&#111;&#117;&#116;&#x2e;&#109;&#x65;</a>&rdquo; ]
```</p>

<p>```rust
//main.rs</p>

<p>fn main() {
  println!(&ldquo;hello world&rdquo;);
}</p>

<p>```</p>

<p>构建项目不需要手动 rustc 了，那是上个世纪的东西，我们直接 <code>cargo build</code> 就可以：<code>docker run -i -t -v $HOME/var/docker:/mnt/data -w /mnt/data/helloworld sunng/nightly cargo build</code></p>

<p>其中 <code>-v</code> 参数用于挂载目录，<code>-w</code> 参数指定执行的 pwd。</p>

<p>如果构建成功，就可以执行了，在 docker 中执行：<code>docker run -i -t -v $HOME/var/docker:/mnt/data -w /mnt/data/helloworld sunng/nightly target/hello-world</code></p>

<p>其实可以直接在 host 系统里执行也是完全可以的：<code>$HOME/var/docker/helloworld/target/hello-world</code>。</p>

<h2>Web Hello World</h2>

<p>前面说了 Rust 都有 web 框架了，我们就写一个 Web 版本的 Hello World 吧。这次用 Iron 框架，首先添加依赖到 Cargo 文件：</p>

<p>```
[package]</p>

<p>name = &ldquo;hello-world&rdquo;
version = &ldquo;0.1.0&rdquo;
authors = [ &ldquo;<a href="&#x6d;&#97;&#105;&#108;&#x74;&#x6f;&#58;&#x73;&#117;&#110;&#110;&#103;&#x40;&#97;&#x62;&#111;&#x75;&#116;&#x2e;&#x6d;&#101;">&#115;&#x75;&#110;&#x6e;&#103;&#64;&#x61;&#x62;&#x6f;&#x75;&#x74;&#x2e;&#x6d;&#x65;</a>&rdquo; ]</p>

<p>[dependencies.iron]</p>

<p>git = &ldquo;<a href="https://github.com/iron/iron.git">https://github.com/iron/iron.git</a>&rdquo;</p>

<p>[dependencies.core]</p>

<p>git = &ldquo;<a href="https://github.com/iron/core.git">https://github.com/iron/core.git</a>&rdquo;
```</p>

<p>Cargo 目前还没有中央仓库，但是<a href="http://crates.io/faq.html#github">据说将来会有</a>。目前还都是用 git 仓库来直接添加，所以构建环境里必须要有 git。</p>

<p>照着 <a href="https://github.com/iron/iron/blob/master/examples/hello.rs">Iron 的例子</a>写一个最简单的 hello world 程序。</p>

<p>```rust
extern crate iron;
extern crate http;</p>

<p>use std::io::net::ip::Ipv4Addr;
use iron::{Iron, Server, Chain, Request, Response, Alloy, Status, Unwind, FromFn};
use <a href="http::status;">http::status;</a></p>

<p>fn hello_world(<em>: &amp;mut Request, res: &amp;mut Response, </em>: &amp;mut Alloy) &ndash;> Status {</p>

<pre><code>res.serve(status::Ok, "Hello, world!");
Unwind
</code></pre>

<p>}</p>

<p>fn main() {
  let mut server: Server = Iron::new();
  server.chain.link(FromFn::new(hello_world));
  server.listen(Ipv4Addr(127, 0, 0, 1), 3000);
}</p>

<p>```</p>

<p>编译 <code>docker run -i -t -v $HOME/var/docker:/mnt/data -w /mnt/data/helloworld sunng/nightly cargo build</code></p>

<p>运行 <code>docker run -i -t -v $HOME/var/docker:/mnt/data -w /mnt/data/helloworld -p 3000:3000 sunng/nightly target/hello-world</code></p>

<p>新增的参数<code>-p</code>是把 docker 环境里的端口3000映射到 host 上的3000，这样我们才能在外面访问。</p>

<p>最后还有一个问题，因为程序听的是127.0.0.1，所以在 host 上是无法访问这个端口的，修改代码：</p>

<p>```rust</p>

<p>  server.listen(Ipv4Addr(0, 0, 0, 0), 3000);
```</p>

<p>就可以正常工作了。</p>

<h2>Wrap up</h2>

<p>总结一下上面用 docker 比虚拟机的好处：</p>

<ul>
<li>占用资源少，启动快</li>
<li>与 host 共享网络、硬盘都非常方便，满足开发需要不成问题</li>
<li>所有都是命令，与 host 系统上的进程集成也非常方便</li>
<li>支持镜像的版本控制和仓库</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure Microservice Architecture With Slacker Cluster]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/07/08/microservice-and-slacker-cluster/"/>
    <updated>2014-07-08T22:12:52+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/07/08/microservice-and-slacker-cluster</id>
    <content type="html"><![CDATA[<p><a href="http://www.infoq.com/presentations/Micro-Services">Microservice</a> has been a hot new concept in these days. Martin Fowler explained microservice <a href="http://martinfowler.com/articles/microservices.html">in this article</a>. From me, microservice is a set of fine-grained function units running on independent process, each of them are connected with light-weighted transports: RESTful API or light messaging queue.</p>

<p>It&rsquo;s a new concept in enterprise architecture, since the last movement in the field promotes SOA architecture. SOA encourages architects to componentize their business logic in service, and deploy service bus(ESB) for integration. Microservice can be more concrete and light-weighted. The service units in Microservice can be any standalone function, or just a tier in traditional tier based development. These units can be deployed on dedicate process or grouped into a process.</p>

<p>In clojure development at <a href="https://avoscloud.com">avoscloud</a>, we are using the <a href="https://github.com/sunng87/slacker-cluster">slacker cluster framework</a> for our microsrvice architecture.</p>

<p><a href="https://github.com/sunng87/slacker">Slacker RPC</a> exposes services as  clojure namespace (pretty light-weighted) All functions in the namespace can be called from remote. A slacker server can expose any number of namespaces:</p>

<p><code>clojure
(start-slacker-server 2014 [my.serviceA my.serviceB ...])
</code></p>

<p>Slacker uses a binary protocol on TCP and configurable serialization (json/edn/<a href="https://github.com/ptaoussanis/nippy">nippy</a>) for communication, which is fast and compact.</p>

<p>And in slacker cluster, exposed namespaces are registered on zookeeper as ephemeral nodes. The client doesn&rsquo;t have to know which service is deployed on which process. Instead, it connects to zookeeper and look up all process address for service it interests in.</p>

<p>```clojure
(def sc (clustered-slacker-client zk-addr &hellip;))
(defn-remote &lsquo;sc my.serviceA/fn-abc)</p>

<p>;;when calling remote function for the first time, the client will look up zookeeper for remote processes and cache the results
(fn-abc)
```</p>

<p>If there are more than one process available, the client library will balance the load on each process. And for stateful service, slacker cluster also elects master node to ensure all requests go to single process. (<a href="http://sunng.info/blog/blog/2014/06/09/grouping-in-slacker-0-dot-12/">Slacker cluster grouping</a>)</p>

<p>Zookeeper directory structure:</p>

<p>```
ls /slacker/example-cluster/namespaces/
[my.serviceA, my.serviceB]</p>

<p>ls /slacker/example-cluster/namespaces/my.serviceA
[192.168.1.100:2104, 192.168.1.101:2014&hellip;]
```</p>

<p>Decoupling processes and services made microservice deployment quite flexible. Functional namespaces can be deployed on any process, standalone or grouped together, like Martin Fowler&rsquo;s chart <a href="http://martinfowler.com/articles/microservices/images/sketch.png">shows</a>.</p>

<p>All these nodes are also watched by clients. If a process crashed or put offline, the clients will get notified by zookeeper, then no requests will be made on that process. Also, when you exhausted service capacity, just simply put on another process, the client will soon balance load to the new node. Scaling services is easy like that.</p>

<p>Thanks to zookeeper&rsquo;s watch mechanism, there&rsquo;s no need to configure service static and update while you add/remove nodes. This is especially important in large-scale deployment. (Since microservices are often find-grained, you will always have a lot of process to update/restart.)</p>

<p>For more about Slacker Cluster, <a href="https://github.com/sunng87/slacker-cluster">check my code repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[扩展 Linux Ephemeral 端口限制]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/07/01/extend-linux-ephemeral-ports/"/>
    <updated>2014-07-01T17:11:58+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/07/01/extend-linux-ephemeral-ports</id>
    <content type="html"><![CDATA[<p>默认情况下，单一Linux能发起的客户端连接数是十分有限的，为此，我们要测试大规模连接程序时不得不启动很多客户端机器模拟连接。下面介绍一些增加单台Linux发起连接数的方法。</p>

<h3>增加文件打开数</h3>

<p>第一步最为基础的，提高打开文件描述符的数量。默认的情况下，这个配置为1024，是不能满足我们的使用的。增加到999999个：</p>

<p><code>
$ sudo ulimit -n 999999
</code></p>

<p>持久化这个配置，可以在<code>/etc/security/</code>（或<code>/etc/security.d/</code>，取决于你的发行版）下建立文件，增加</p>

<p><code>
*       hard    nofile      999999
*       soft    nofile      999999
</code></p>

<p>这将对所有用户起效。</p>

<h3>增加客户端端口数</h3>

<p>当Linux发起客户端连接时，如果没有显式指定，会给客户端socket绑定一个 ephemeral 端口。这个端口的范围是从这个区间选取的：</p>

<p>```
 $ cat /proc/sys/net/ipv4/ip_local_port_range
32768   61000</p>

<p>```</p>

<p>如果这个区间的端口耗尽，socket就会产生<code>cannot assign requested address</code>的错误。要增加端口范围，我们需要把他设置得更大：</p>

<p><code>
$ sudo echo "1025 65535" &gt; /proc/sys/net/ipv4/ip_local_port_range
</code></p>

<p>这样，单台机器就可以发出六万多个连接。</p>

<h3>增加虚拟网卡</h3>

<p>对于内存大一点的客户端机器，六万多个连接远不是其性能极限。由于IP消息中，一条消息是由 <code>src_addr</code>, <code>src_port</code>, <code>dst_addr</code>, <code>dst_port</code> 四元组标识，所以要增加连接，我们需要更多IP。在Linux上，我们可以启动虚拟网卡绑定额外的IP。</p>

<p><code>
$ sudo ifconfig eth0:0 192.168.1.100
$ sudo ifconfig eth0:1 192.168.1.101
...
</code></p>

<p>要关闭这些虚拟网卡</p>

<p><code>
$ sudo ifconfig eth0:0 down
</code></p>

<h3>使用虚拟网卡连接</h3>

<p>拥有多个IP之后，客户端socket需要显示绑定这些IP才行，以python为例，在connect前调用：</p>

<p><code>python
sock.bind((local_addr, local_port))
</code></p>

<p>可以指定连接的源地址和端口。在普通的Linux编程里，当你指定<code>local_port</code>为<code>0</code>时，Linux会分配一个之前提到的 ephemeral 端口。但是当使用虚拟IP时，如果仍然指定0，系统并不会因为IP不同而重用端口号，达到六万多的限制后，仍然会抛出不能获得地址的异常。</p>

<p>实际上是可以获得的，这里需要用户显式地指定端口好。如果需要大规模的连接，那就一个一个绑定好了。</p>

<h3>启用time_wait reuse和recycle</h3>

<p>Linux的socket进入<code>time_wait</code>后需要有一定的时间回收，之后端口才能重新使用。这在大规模测试的时候就比较麻烦，为了免去等待，可以打开<code>tw_reuse</code>和<code>tw_recycle</code>这两个选项。</p>

<p><code>
$ echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_recycle
$ echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse
</code></p>

<p>注意这两个选项都比较激进，最好仅在测试机上使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slacker Cluster 0.12: Grouping]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12/"/>
    <updated>2014-06-09T21:06:39+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12</id>
    <content type="html"><![CDATA[<h2>What are Slacker and Slacker Cluster</h2>

<p><a href="https://github.com/sunng87/slacker">Slacker</a> is my side project started in late 2011. The goal of Slacker project is to provide a high performance RPC system for clojure, with elegant API. Slacker doesn&rsquo;t ruin your code. Your remote invocation looks exactly same as local, from code. That means you can switch back and forth at same time.</p>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> is a support module for running Slacker servers with multiple instances. Cluster enabled slacker server will publish all its served namespaces to Zookeeper cluster. The Cluster enabled client reads and watches these meta data. The most important feature of Slacker Cluster is you can add or remove servers without changing client configuration.</p>

<h2>Grouping in Slacker Cluster</h2>

<p>Started in 0.11, then enhanced in 0.12, Slacker Cluster now has flexible <strong>grouping</strong> choices for your scenario. In Slacker Cluster, <strong>grouping</strong> means which server(s) to call on a particular invocation.</p>

<p>There and four kinds of grouping for you: <code>:random</code>, <code>:leader</code>, <code>:all</code> and custom.</p>

<h3>:random</h3>

<p>By default, Slacker cluster clients use <code>:random</code> grouping: select a random server from server list. Random grouping works great for stateless services. It automatically balances load of each server.</p>

<h3>:leader</h3>

<p>Slacker servers selects leader for each namespace they expose. So at any time there will be one and only one leader node for every namespaces. The <code>:leader</code> grouping routes all invocations onto the leader node. This is required when your server has state, and you have to ensure the consistency and availability.</p>

<h3>:all</h3>

<p>As the name suggests, <code>:all</code> grouping routes invocations on every node at same time. In other words, it&rsquo;s broadcast. Note that this grouping might change your function return values. In <code>:random</code> and <code>:leader</code> mode, there&rsquo;s only one server called, just like local invocation. In <code>:all</code>, there&rsquo;s chances several servers are called and several values returned. I will talk about how to deal with these return values later.</p>

<h3>Custom</h3>

<p>You can also provide a function for dynamic grouping. For requested namespace, function and arguments, you can specify any server(s) or grouping option.</p>

<h2>Grouping results</h2>

<p>Grouping may break original behavior of you code by returning multiple values from multiple servers. But you still have full control over it. There are four types of value you can specify for results aggregation: <code>:single</code>, <code>:vector</code>, <code>:map</code> and custom function.</p>

<p>In short words:</p>

<ul>
<li><code>:single</code> returns the first valid result, and behavior same as calling single server or local invocation. This is the default value.</li>
<li><code>:vector</code> returns  a vector of all results.</li>
<li><code>:map</code> returns a map of all results, indexed by server addresses.</li>
<li>Custom aggregation function accepts the results and allows you to merge the values.</li>
</ul>


<h2>Grouping exceptions</h2>

<p>What happens when remote function threw exceptions? The grouping exception option defines that. When set to <code>:all</code>, the client will raise an error only if all remote nodes broken. Otherwise, the broken result will be ignored and only valid results will apply <code>grouping-results</code> rules. The opposite option is <code>:any</code>, which mean client will raise error when any of calls is broken.</p>

<h2>Granularity</h2>

<p>The grouping options can be set to client level:</p>

<p><code>clojure
(clustered-slackerc "cluster-name" "127.0.0.1:2181" :grouping :leader)
</code></p>

<p>or function level:</p>

<p><code>clojure
(defn-remote sc slacker.example.api/timestamp
  :grouping :all
  :grouping-results :single)
</code></p>

<h2>Conclusion</h2>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> has been used in our Avos Cloud backend for service integration. Feel free to let me know if you have interests or questions with this library.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fork-Join in Papaline]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline/"/>
    <updated>2014-05-27T21:47:45+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline</id>
    <content type="html"><![CDATA[<p><a href="http://github.com/sunng87/papaline">Papaline</a> 0.3 introduced a new model &ldquo;fork-join&rdquo; for task execution. It allows you to split a task into smaller units, and execute them in parallel.</p>

<p>Before that, a task is processed as a single unit from the first stage to the second, the third and the last. Within a stage, all computing is done in a single thread.</p>

<p><img src="http://i.imgur.com/w6RlNZo.png" alt="linear execution" /></p>

<p>This model has limitation that you are required to execute any of your stage in serial. If your task has a few split-able units, it&rsquo;s always better to run them in parallel. Here we have <code>(fork)</code> command for the situation.</p>

<p>For example, you are using the <em>fanout-on-write</em> model to build an activity stream. Once a user posted a new status, you need to find all followers(stage 1) of that user and append the status to their timeline(stage 2).</p>

<p>In previous version of papaline, these two stages are:</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>[followers msg]))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (doseq [user-id user-ids]</p>

<pre><code>(write-redis-list user-id msg)))
</code></pre>

<p>```</p>

<p>In the second task, the msg is appended to user&rsquo;s timeline one by one.</p>

<p>Using <code>(fork)</code>, the <code>fanout-to-user-timeline</code> can be executed in parallel.</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>(fork (map #(vector % msg) followers))))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (write-redis-list user-id msg))</p>

<p>```</p>

<p>After the <code>find-followers</code> function, the result will be splitted into <code>(count followers)</code> parts and sent into input channel of stage 2. So the tasks execution will be like:</p>

<p><img src="http://i.imgur.com/MLhZ0Pm.png" alt="forked execution" /></p>

<p>To collect the results of all forked sub-tasks, you can use <code>(join)</code>. If the return value is wrapped with join, it won&rsquo;t trigger next stage immediately but to wait all forked tasks to finish.</p>

<p><img src="http://i.imgur.com/BVDEH9Q.png" alt="join" /></p>

<p>So with <code>(fork)</code> and <code>(join)</code>, it&rsquo;s very flexible to change execution model in Papaline.  Internally, I use clojure&rsquo;s <a href="http://clojure.org/metadata">metadata</a> to add flags for the return value, without ruining the non-invasive design of <a href="http://github.com/sunng87/papaline">Papaline</a>.</p>
]]></content>
  </entry>
  
</feed>
