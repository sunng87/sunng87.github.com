<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Clojure | Here comes the Sun]]></title>
  <link href="http://sunng87.github.io/blog//blog/categories/clojure/atom.xml" rel="self"/>
  <link href="http://sunng87.github.io/blog//"/>
  <updated>2014-07-08T23:32:35+08:00</updated>
  <id>http://sunng87.github.io/blog//</id>
  <author>
    <name><![CDATA[Sun Ning]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Clojure Microservice Architecture With Slacker Cluster]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/07/08/microservice-and-slacker-cluster/"/>
    <updated>2014-07-08T22:12:52+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/07/08/microservice-and-slacker-cluster</id>
    <content type="html"><![CDATA[<p><a href="http://www.infoq.com/presentations/Micro-Services">Microservice</a> has been a hot new concept in these days. Martin Fowler explained microservice <a href="http://martinfowler.com/articles/microservices.html">in this article</a>. From me, microservice is a set of fine-grained function units running on independent process, each of them are connected with light-weighted transports: RESTful API or light messaging queue.</p>

<p>It&rsquo;s a new concept in enterprise architecture, since the last movement in the field promotes SOA architecture. SOA encourages architects to componentize their business logic in service, and deploy service bus(ESB) for integration. Microservice can be more concrete and light-weighted. The service units in Microservice can be any standalone function, or just a tier in traditional tier based development. These units can be deployed on dedicate process or grouped into a process.</p>

<p>In clojure development at <a href="https://avoscloud.com">avoscloud</a>, we are using the <a href="https://github.com/sunng87/slacker-cluster">slacker cluster framework</a> for our microsrvice architecture.</p>

<p><a href="https://github.com/sunng87/slacker">Slacker RPC</a> exposes services as  clojure namespace (pretty light-weighted) All functions in the namespace can be called from remote. A slacker server can expose any number of namespaces:</p>

<p><code>clojure
(start-slacker-server 2014 [my.serviceA my.serviceB ...])
</code></p>

<p>Slacker uses a binary protocol on TCP and configurable serialization (json/edn/<a href="https://github.com/ptaoussanis/nippy">nippy</a>) for communication, which is fast and compact.</p>

<p>And in slacker cluster, exposed namespaces are registered on zookeeper as ephemeral nodes. The client doesn&rsquo;t have to know which service is deployed on which process. Instead, it connects to zookeeper and look up all process address for service it interests in.</p>

<p>```clojure
(def sc (clustered-slacker-client zk-addr &hellip;))
(defn-remote &lsquo;sc my.serviceA/fn-abc)</p>

<p>;;when calling remote function for the first time, the client will look up zookeeper for remote processes and cache the results
(fn-abc)
```</p>

<p>If there are more than one process available, the client library will balance the load on each process. And for stateful service, slacker cluster also elects master node to ensure all requests go to single process. (<a href="http://sunng.info/blog/blog/2014/06/09/grouping-in-slacker-0-dot-12/">Slacker cluster grouping</a>)</p>

<p>Zookeeper directory structure:</p>

<p>```
ls /slacker/example-cluster/namespaces/
[my.serviceA, my.serviceB]</p>

<p>ls /slacker/example-cluster/namespaces/my.serviceA
[192.168.1.100:2104, 192.168.1.101:2014&hellip;]
```</p>

<p>Decoupling processes and services made microservice deployment quite flexible. Functional namespaces can be deployed on any process, standalone or grouped together, like Martin Fowler&rsquo;s chart <a href="http://martinfowler.com/articles/microservices/images/sketch.png">shows</a>.</p>

<p>All these nodes are also watched by clients. If a process crashed or put offline, the clients will get notified by zookeeper, then no requests will be made on that process. Also, when you exhausted service capacity, just simply put on another process, the client will soon balance load to the new node. Scaling services is easy like that.</p>

<p>Thanks to zookeeper&rsquo;s watch mechanism, there&rsquo;s no need to configure service static and update while you add/remove nodes. This is especially important in large-scale deployment. (Since microservices are often find-grained, you will always have a lot of process to update/restart.)</p>

<p>For more about Slacker Cluster, <a href="https://github.com/sunng87/slacker-cluster">check my code repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slacker Cluster 0.12: Grouping]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12/"/>
    <updated>2014-06-09T21:06:39+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/06/09/grouping-in-slacker-0-dot-12</id>
    <content type="html"><![CDATA[<h2>What are Slacker and Slacker Cluster</h2>

<p><a href="https://github.com/sunng87/slacker">Slacker</a> is my side project started in late 2011. The goal of Slacker project is to provide a high performance RPC system for clojure, with elegant API. Slacker doesn&rsquo;t ruin your code. Your remote invocation looks exactly same as local, from code. That means you can switch back and forth at same time.</p>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> is a support module for running Slacker servers with multiple instances. Cluster enabled slacker server will publish all its served namespaces to Zookeeper cluster. The Cluster enabled client reads and watches these meta data. The most important feature of Slacker Cluster is you can add or remove servers without changing client configuration.</p>

<h2>Grouping in Slacker Cluster</h2>

<p>Started in 0.11, then enhanced in 0.12, Slacker Cluster now has flexible <strong>grouping</strong> choices for your scenario. In Slacker Cluster, <strong>grouping</strong> means which server(s) to call on a particular invocation.</p>

<p>There and four kinds of grouping for you: <code>:random</code>, <code>:leader</code>, <code>:all</code> and custom.</p>

<h3>:random</h3>

<p>By default, Slacker cluster clients use <code>:random</code> grouping: select a random server from server list. Random grouping works great for stateless services. It automatically balances load of each server.</p>

<h3>:leader</h3>

<p>Slacker servers selects leader for each namespace they expose. So at any time there will be one and only one leader node for every namespaces. The <code>:leader</code> grouping routes all invocations onto the leader node. This is required when your server has state, and you have to ensure the consistency and availability.</p>

<h3>:all</h3>

<p>As the name suggests, <code>:all</code> grouping routes invocations on every node at same time. In other words, it&rsquo;s broadcast. Note that this grouping might change your function return values. In <code>:random</code> and <code>:leader</code> mode, there&rsquo;s only one server called, just like local invocation. In <code>:all</code>, there&rsquo;s chances several servers are called and several values returned. I will talk about how to deal with these return values later.</p>

<h3>Custom</h3>

<p>You can also provide a function for dynamic grouping. For requested namespace, function and arguments, you can specify any server(s) or grouping option.</p>

<h2>Grouping results</h2>

<p>Grouping may break original behavior of you code by returning multiple values from multiple servers. But you still have full control over it. There are four types of value you can specify for results aggregation: <code>:single</code>, <code>:vector</code>, <code>:map</code> and custom function.</p>

<p>In short words:</p>

<ul>
<li><code>:single</code> returns the first valid result, and behavior same as calling single server or local invocation. This is the default value.</li>
<li><code>:vector</code> returns  a vector of all results.</li>
<li><code>:map</code> returns a map of all results, indexed by server addresses.</li>
<li>Custom aggregation function accepts the results and allows you to merge the values.</li>
</ul>


<h2>Grouping exceptions</h2>

<p>What happens when remote function threw exceptions? The grouping exception option defines that. When set to <code>:all</code>, the client will raise an error only if all remote nodes broken. Otherwise, the broken result will be ignored and only valid results will apply <code>grouping-results</code> rules. The opposite option is <code>:any</code>, which mean client will raise error when any of calls is broken.</p>

<h2>Granularity</h2>

<p>The grouping options can be set to client level:</p>

<p><code>clojure
(clustered-slackerc "cluster-name" "127.0.0.1:2181" :grouping :leader)
</code></p>

<p>or function level:</p>

<p><code>clojure
(defn-remote sc slacker.example.api/timestamp
  :grouping :all
  :grouping-results :single)
</code></p>

<h2>Conclusion</h2>

<p><a href="https://github.com/sunng87/slacker-cluster">Slacker Cluster</a> has been used in our Avos Cloud backend for service integration. Feel free to let me know if you have interests or questions with this library.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fork-Join in Papaline]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline/"/>
    <updated>2014-05-27T21:47:45+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/05/27/fork-join-in-papaline</id>
    <content type="html"><![CDATA[<p><a href="http://github.com/sunng87/papaline">Papaline</a> 0.3 introduced a new model &ldquo;fork-join&rdquo; for task execution. It allows you to split a task into smaller units, and execute them in parallel.</p>

<p>Before that, a task is processed as a single unit from the first stage to the second, the third and the last. Within a stage, all computing is done in a single thread.</p>

<p><img src="http://i.imgur.com/w6RlNZo.png" alt="linear execution" /></p>

<p>This model has limitation that you are required to execute any of your stage in serial. If your task has a few split-able units, it&rsquo;s always better to run them in parallel. Here we have <code>(fork)</code> command for the situation.</p>

<p>For example, you are using the <em>fanout-on-write</em> model to build an activity stream. Once a user posted a new status, you need to find all followers(stage 1) of that user and append the status to their timeline(stage 2).</p>

<p>In previous version of papaline, these two stages are:</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>[followers msg]))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (doseq [user-id user-ids]</p>

<pre><code>(write-redis-list user-id msg)))
</code></pre>

<p>```</p>

<p>In the second task, the msg is appended to user&rsquo;s timeline one by one.</p>

<p>Using <code>(fork)</code>, the <code>fanout-to-user-timeline</code> can be executed in parallel.</p>

<p>```clojure
(defn find-followers [id msg]
  (let [followers (query-db-for-followers id)]</p>

<pre><code>(fork (map #(vector % msg) followers))))
</code></pre>

<p>(defn fanout-to-user-timeline [user-ids msg]
  (write-redis-list user-id msg))</p>

<p>```</p>

<p>After the <code>find-followers</code> function, the result will be splitted into <code>(count followers)</code> parts and sent into input channel of stage 2. So the tasks execution will be like:</p>

<p><img src="http://i.imgur.com/MLhZ0Pm.png" alt="forked execution" /></p>

<p>To collect the results of all forked sub-tasks, you can use <code>(join)</code>. If the return value is wrapped with join, it won&rsquo;t trigger next stage immediately but to wait all forked tasks to finish.</p>

<p><img src="http://i.imgur.com/BVDEH9Q.png" alt="join" /></p>

<p>So with <code>(fork)</code> and <code>(join)</code>, it&rsquo;s very flexible to change execution model in Papaline.  Internally, I use clojure&rsquo;s <a href="http://clojure.org/metadata">metadata</a> to add flags for the return value, without ruining the non-invasive design of <a href="http://github.com/sunng87/papaline">Papaline</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Papaline: Concurrent Pipeline With core.async]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/04/20/concurrent-pipeline-with-core-async/"/>
    <updated>2014-04-20T17:21:44+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/04/20/concurrent-pipeline-with-core-async</id>
    <content type="html"><![CDATA[<p>According to <a href="http://en.wikipedia.org/wiki/Staged_event-driven_architecture">wikipedia</a>, Staged Event-driven Architecture is an approach to software architecture that decomposes a complex, event-driven application into a set of stages connected by queues. We were using Java framework, <a href="https://github.com/sunng87/stages">stages</a>, to implement queue based SEDA. As we are using more and more Clojure nowadays, I decide to re-implement it in Clojure language, and in Clojure way. It&rsquo;s <a href="https://github.com/sunng87/papaline">papaline</a>.</p>

<p>The most important difference between papaline and stages is the usage of IoC threads. Core.async introduces IoC threads for Clojure, which is a popular concurrent mechanism recently. In traditional queue based thread pool, threads are blocked on queue to wait for tasks. While for IoC threads, channels act similar to queues but no actual thread is blocked on channel. Once there is a task available in channel, an underlying thread will be picked to execute it. So for core.async, you don&rsquo;t have to assign a static thread pool to each channel. The channel will pick thread from a shared system thread pool on demand. In current core.async release, it&rsquo;s a fixed thread pool with <em>(processors * 4) + 42</em> threads. That&rsquo;s much flexible and efficient.</p>

<p>Papaline takes advantages of this feature. The base concept in papaline is <strong>stage</strong> and <strong>pipeline</strong>. A pipeline is created with a ordered sequence of stages. Stages configured in a pipeline are connected with channels, instead of queues. Threads are automatically managed by core.async, and scheduled based on load of channels.</p>

<p>When you run a pipeline, the input data is sent to the inbound channel of the first stage. The stage will received the data and pick a thread to execute the function. Then the result is put into the second stage&rsquo;s inbound channel. The user-visible behavior is much like <code>comp</code>, but in concurrent.</p>

<p>Also core.async offers different type of channel buffers: fixed <code>buffer</code>, <code>sliding-buffer</code> and <code>dropping-buffer</code>. They are channels equivalent to j.u.c thread pool&rsquo;s <code>RejectedExecutionHandler</code>.</p>

<p>We have already deployed papaline in our asynchronous system and it works great by far. Find the project on <a href="https://github.com/sunng87/papaline">github</a> if you are interested in.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slacker Library Updated]]></title>
    <link href="http://sunng87.github.io/blog//blog/2014/03/04/slacker-0-dot-11-released/"/>
    <updated>2014-03-04T23:40:00+08:00</updated>
    <id>http://sunng87.github.io/blog//blog/2014/03/04/slacker-0-dot-11-released</id>
    <content type="html"><![CDATA[<p>After almost two years idle in commit log, I restarted development of my slacker frameworks recently. It will be used in our AVOS Cloud production as integration solution between clojure systems.</p>

<p>The recent update in slacker, slacker-cluster and link are:</p>

<h3>link</h3>

<p>There are two releases in the <a href="https://github.com/sunng87/link">link</a> library, features include:</p>

<ul>
<li>Ported to Netty 4</li>
<li>WebSocket server handler</li>
<li>Ability to shutdown server</li>
<li>Ability to use core.async with link ring adapter</li>
</ul>


<h3>slacker</h3>

<p>The most recent release of <a href="https://github.com/sunng87/slacker">slacker</a> is 0.11.0:</p>

<ul>
<li>New ping-interval option for clients</li>
<li>Async callback will accept two argument, and can handle exceptions</li>
<li>Slingshot removed, we are now using clojure built-in ex-info</li>
<li>All client creation functions and defn-remote are delayed</li>
<li>Bugfix for issue when several clients started in a process</li>
</ul>


<h3>slacker-cluster</h3>

<p>There&rsquo;s major enhancement in <a href="https://github.com/sunng87/slacker-cluster">slacker cluster</a> 0.11.0</p>

<ul>
<li>Server exception no longer blocks client</li>
<li>Added options to call functions on multiple servers, control return type and exception handling</li>
</ul>


<p>All these libraries are available on github. I will write more about how we use them in AVOS Cloud in future.</p>
]]></content>
  </entry>
  
</feed>
